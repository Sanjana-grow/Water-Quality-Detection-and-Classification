{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c35ca98b",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:13.397940Z",
     "iopub.status.busy": "2025-07-26T10:45:13.397651Z",
     "iopub.status.idle": "2025-07-26T10:45:15.270747Z",
     "shell.execute_reply": "2025-07-26T10:45:15.269323Z"
    },
    "papermill": {
     "duration": 1.881113,
     "end_time": "2025-07-26T10:45:15.272803",
     "exception": false,
     "start_time": "2025-07-26T10:45:13.391690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/30.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/38.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/33.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/37.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/29.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/31.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/32.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/39.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Clean-samples/36.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Dirty-samples/16.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Dirty-samples/17.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Dirty-samples/15.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Dirty-samples/19.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/test/Dirty-samples/18.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/20.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/6.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/5.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/8.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/10.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/0.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/35.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/9.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/1.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/16.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/23.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/7.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/28.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/22.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/24.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/13.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/17.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/26.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/15.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/12.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/11.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/34.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/27.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/21.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/4.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/3.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/19.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/14.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/18.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/2.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Clean-samples/25.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/6.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/5.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/8.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/10.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/0.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/9.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/1.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/7.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/13.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/15.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/12.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/11.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/4.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/3.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/14.jpg\n",
      "/kaggle/input/clean-dirty-water-dataset/water images/train/Dirty-samples/2.jpg\n"
     ]
    }
   ],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8bf8bc7a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:15.285514Z",
     "iopub.status.busy": "2025-07-26T10:45:15.285104Z",
     "iopub.status.idle": "2025-07-26T10:45:28.109284Z",
     "shell.execute_reply": "2025-07-26T10:45:28.108335Z"
    },
    "papermill": {
     "duration": 12.832138,
     "end_time": "2025-07-26T10:45:28.111013",
     "exception": false,
     "start_time": "2025-07-26T10:45:15.278875",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7a1a6b67",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:28.120186Z",
     "iopub.status.busy": "2025-07-26T10:45:28.119752Z",
     "iopub.status.idle": "2025-07-26T10:45:28.344572Z",
     "shell.execute_reply": "2025-07-26T10:45:28.343596Z"
    },
    "papermill": {
     "duration": 0.231022,
     "end_time": "2025-07-26T10:45:28.346094",
     "exception": false,
     "start_time": "2025-07-26T10:45:28.115072",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/kaggle/working/elvina_data/test/dirty'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataset location\n",
    "elvina_root = '/kaggle/input/clean-dirty-water-dataset/water images'\n",
    "\n",
    "# New organized dataset path\n",
    "base_path = '/kaggle/working/elvina_data'\n",
    "os.makedirs(base_path, exist_ok=True)\n",
    "\n",
    "# Copy Elvina clean & dirty data\n",
    "shutil.copytree(os.path.join(elvina_root, 'train', 'Clean-samples'), os.path.join(base_path, 'train/clean'))\n",
    "shutil.copytree(os.path.join(elvina_root, 'train', 'Dirty-samples'), os.path.join(base_path, 'train/dirty'))\n",
    "shutil.copytree(os.path.join(elvina_root, 'test', 'Clean-samples'), os.path.join(base_path, 'test/clean'))\n",
    "shutil.copytree(os.path.join(elvina_root, 'test', 'Dirty-samples'), os.path.join(base_path, 'test/dirty'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9d8e01d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:28.355737Z",
     "iopub.status.busy": "2025-07-26T10:45:28.355424Z",
     "iopub.status.idle": "2025-07-26T10:45:28.364521Z",
     "shell.execute_reply": "2025-07-26T10:45:28.363322Z"
    },
    "papermill": {
     "duration": 0.01599,
     "end_time": "2025-07-26T10:45:28.366197",
     "exception": false,
     "start_time": "2025-07-26T10:45:28.350207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classes: ['clean', 'dirty']\n"
     ]
    }
   ],
   "source": [
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "    'test': transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "    ]),\n",
    "}\n",
    "\n",
    "image_datasets = {\n",
    "    x: datasets.ImageFolder(os.path.join(base_path, x), transform=data_transforms[x])\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "dataloaders = {\n",
    "    x: DataLoader(image_datasets[x], batch_size=16, shuffle=True)\n",
    "    for x in ['train', 'test']\n",
    "}\n",
    "\n",
    "class_names = image_datasets['train'].classes\n",
    "print(\"Classes:\", class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60788885",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:28.375129Z",
     "iopub.status.busy": "2025-07-26T10:45:28.374831Z",
     "iopub.status.idle": "2025-07-26T10:45:28.975997Z",
     "shell.execute_reply": "2025-07-26T10:45:28.974968Z"
    },
    "papermill": {
     "duration": 0.60727,
     "end_time": "2025-07-26T10:45:28.977626",
     "exception": false,
     "start_time": "2025-07-26T10:45:28.370356",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 168MB/s]\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "model = models.resnet18(pretrained=True)\n",
    "num_features = model.fc.in_features\n",
    "model.fc = nn.Linear(num_features, 2)  # Binary classification (clean, dirty)\n",
    "model = model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "375e43d7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:28.987825Z",
     "iopub.status.busy": "2025-07-26T10:45:28.986891Z",
     "iopub.status.idle": "2025-07-26T10:45:58.747293Z",
     "shell.execute_reply": "2025-07-26T10:45:58.746259Z"
    },
    "papermill": {
     "duration": 29.767042,
     "end_time": "2025-07-26T10:45:58.748980",
     "exception": false,
     "start_time": "2025-07-26T10:45:28.981938",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5 - Loss: 1.2333 - Acc: 0.7234\n",
      "Epoch 2/5 - Loss: 1.5411 - Acc: 0.8511\n",
      "Epoch 3/5 - Loss: 1.7039 - Acc: 0.8723\n",
      "Epoch 4/5 - Loss: 0.4897 - Acc: 0.9149\n",
      "Epoch 5/5 - Loss: 1.5073 - Acc: 0.8511\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5  # You can increase this for better accuracy\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_acc = running_corrects.double() / len(image_datasets['train'])\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs} - Loss: {running_loss:.4f} - Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6a1b369a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:45:58.760803Z",
     "iopub.status.busy": "2025-07-26T10:45:58.760496Z",
     "iopub.status.idle": "2025-07-26T10:45:59.040271Z",
     "shell.execute_reply": "2025-07-26T10:45:59.039125Z"
    },
    "papermill": {
     "duration": 0.286904,
     "end_time": "2025-07-26T10:45:59.041961",
     "exception": true,
     "start_time": "2025-07-26T10:45:58.755057",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=MobileNet_V2_Weights.IMAGENET1K_V1`. You can also use `weights=MobileNet_V2_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/mobilenet_v2-b0353104.pth\" to /root/.cache/torch/hub/checkpoints/mobilenet_v2-b0353104.pth\n",
      "100%|██████████| 13.6M/13.6M [00:00<00:00, 157MB/s]\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_13/3033714303.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load MobileNetV2 as second model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmobilenet_v2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpretrained\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlast_channel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace final layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mmodel2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "\n",
    "# Load MobileNetV2 as second model\n",
    "model2 = mobilenet_v2(pretrained=True)\n",
    "model2.classifier[1] = nn.Linear(model2.last_channel, num_classes)  # Replace final layer\n",
    "\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Train model2 (copy same training loop as before)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_acc = running_corrects.double() / len(image_datasets['train'])\n",
    "    print(f\"[MobileNet] Epoch {epoch+1}/{num_epochs} - Loss: {running_loss:.4f} - Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5557982",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:32:07.992083Z",
     "iopub.status.busy": "2025-07-26T10:32:07.991236Z",
     "iopub.status.idle": "2025-07-26T10:32:31.504019Z",
     "shell.execute_reply": "2025-07-26T10:32:31.503188Z",
     "shell.execute_reply.started": "2025-07-26T10:32:07.992054Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torchvision.models import mobilenet_v2\n",
    "import torch.nn as nn\n",
    "\n",
    "num_classes = len(class_names)  # Or manually set to 2 if using Elvina clean/dirty dataset\n",
    "\n",
    "# Load MobileNetV2 as second model\n",
    "model2 = mobilenet_v2(pretrained=True)\n",
    "model2.classifier[1] = nn.Linear(model2.last_channel, num_classes)\n",
    "\n",
    "model2 = model2.to(device)\n",
    "\n",
    "# Define optimizer and loss\n",
    "criterion2 = nn.CrossEntropyLoss()\n",
    "optimizer2 = torch.optim.Adam(model2.parameters(), lr=0.001)\n",
    "\n",
    "# Train MobileNetV2\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model2.train()\n",
    "    running_loss, running_corrects = 0.0, 0\n",
    "\n",
    "    for inputs, labels in dataloaders['train']:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer2.zero_grad()\n",
    "        outputs = model2(inputs)\n",
    "        loss = criterion2(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer2.step()\n",
    "\n",
    "        _, preds = torch.max(outputs, 1)\n",
    "        running_loss += loss.item()\n",
    "        running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    epoch_acc = running_corrects.double() / len(image_datasets['train'])\n",
    "    print(f\"[MobileNetV2] Epoch {epoch+1}/{num_epochs} - Loss: {running_loss:.4f} - Acc: {epoch_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88f06413",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:32:45.882662Z",
     "iopub.status.busy": "2025-07-26T10:32:45.882394Z",
     "iopub.status.idle": "2025-07-26T10:32:46.041668Z",
     "shell.execute_reply": "2025-07-26T10:32:46.040468Z",
     "shell.execute_reply.started": "2025-07-26T10:32:45.882643Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Function to extract features\n",
    "def extract_features(model, dataloader):\n",
    "    model.eval()\n",
    "    features, labels_all = [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            outputs = model(inputs)\n",
    "            features.append(outputs.cpu().numpy())\n",
    "            labels_all.extend(labels.cpu().numpy())\n",
    "\n",
    "    features = np.vstack(features)\n",
    "    labels_all = np.array(labels_all)\n",
    "    return features, labels_all\n",
    "\n",
    "# Remove softmax layer by using only the penultimate outputs\n",
    "model1.eval()\n",
    "model2.eval()\n",
    "\n",
    "# Replace final classifier temporarily to get penultimate outputs\n",
    "resnet_feat_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "mobilenet_feat_extractor = nn.Sequential(*list(model2.children())[:-1])\n",
    "\n",
    "def get_flat_features(model, dataloader):\n",
    "    model.eval()\n",
    "    flat_features, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            out = model(inputs)\n",
    "            out = torch.flatten(out, 1)\n",
    "            flat_features.append(out.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return np.vstack(flat_features), np.array(all_labels)\n",
    "\n",
    "# Extract features from both models\n",
    "features1_train, labels_train = get_flat_features(resnet_feat_extractor, dataloaders['train'])\n",
    "features2_train, _ = get_flat_features(mobilenet_feat_extractor, dataloaders['train'])\n",
    "\n",
    "features1_test, labels_test = get_flat_features(resnet_feat_extractor, dataloaders['val'])\n",
    "features2_test, _ = get_flat_features(mobilenet_feat_extractor, dataloaders['val'])\n",
    "\n",
    "# Combine features\n",
    "X_train_stack = np.hstack([features1_train, features2_train])\n",
    "X_test_stack = np.hstack([features1_test, features2_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c275ceda",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:33:10.355023Z",
     "iopub.status.busy": "2025-07-26T10:33:10.354655Z",
     "iopub.status.idle": "2025-07-26T10:33:13.489935Z",
     "shell.execute_reply": "2025-07-26T10:33:13.488734Z",
     "shell.execute_reply.started": "2025-07-26T10:33:10.354998Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Remove softmax layer by using only the penultimate outputs\n",
    "model.eval()           # this is ResNet\n",
    "model2.eval()          # this is MobileNet\n",
    "\n",
    "# Get all layers except final FC layer\n",
    "resnet_feat_extractor = nn.Sequential(*list(model.children())[:-1])\n",
    "mobilenet_feat_extractor = nn.Sequential(*list(model2.children())[:-1])\n",
    "\n",
    "def get_flat_features(model, dataloader):\n",
    "    model.eval()\n",
    "    flat_features, all_labels = [], []\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in tqdm(dataloader):\n",
    "            inputs = inputs.to(device)\n",
    "            out = model(inputs)\n",
    "            out = torch.flatten(out, 1)\n",
    "            flat_features.append(out.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "    return np.vstack(flat_features), np.array(all_labels)\n",
    "\n",
    "# Extract features from both models\n",
    "features1_train, labels_train = get_flat_features(resnet_feat_extractor, dataloaders['train'])\n",
    "features2_train, _ = get_flat_features(mobilenet_feat_extractor, dataloaders['train'])\n",
    "\n",
    "features1_test, labels_test = get_flat_features(resnet_feat_extractor, dataloaders['val'])\n",
    "features2_test, _ = get_flat_features(mobilenet_feat_extractor, dataloaders['val'])\n",
    "\n",
    "# Combine features\n",
    "X_train_stack = np.hstack([features1_train, features2_train])\n",
    "X_test_stack = np.hstack([features1_test, features2_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5322e99e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:34:33.617982Z",
     "iopub.status.busy": "2025-07-26T10:34:33.617513Z",
     "iopub.status.idle": "2025-07-26T10:34:37.598613Z",
     "shell.execute_reply": "2025-07-26T10:34:37.597722Z",
     "shell.execute_reply.started": "2025-07-26T10:34:33.617904Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Extract flat features from test set (using 'test' instead of 'val')\n",
    "features1_test, labels_test = get_flat_features(resnet_feat_extractor, dataloaders['test'])\n",
    "features2_test, _ = get_flat_features(mobilenet_feat_extractor, dataloaders['test'])\n",
    "\n",
    "# Stack features from both models\n",
    "X_train = np.hstack([features1_train, features2_train])\n",
    "X_test = np.hstack([features1_test, features2_test])\n",
    "\n",
    "# Train meta-classifier (Logistic Regression)\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "meta_model = LogisticRegression(max_iter=1000)\n",
    "meta_model.fit(X_train, labels_train)\n",
    "y_pred = meta_model.predict(X_test)\n",
    "\n",
    "# Evaluation\n",
    "print(\"Classification Report:\\n\", classification_report(labels_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(labels_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb16cbb",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:35:07.721286Z",
     "iopub.status.busy": "2025-07-26T10:35:07.720949Z",
     "iopub.status.idle": "2025-07-26T10:35:07.751707Z",
     "shell.execute_reply": "2025-07-26T10:35:07.750556Z",
     "shell.execute_reply.started": "2025-07-26T10:35:07.721252Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper function to display image and prediction\n",
    "def visualize_predictions(meta_model, feat_extractor1, feat_extractor2, dataloader, class_names, num_images=6):\n",
    "    model1.eval()\n",
    "    model2.eval()\n",
    "\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            feats1 = feat_extractor1(inputs).cpu().numpy()\n",
    "            feats2 = feat_extractor2(inputs).cpu().numpy()\n",
    "            combined_feats = np.hstack([feats1, feats2])\n",
    "\n",
    "            preds = meta_model.predict(combined_feats)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                img = inputs[i].cpu().permute(1, 2, 0).numpy()\n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # unnormalize\n",
    "                img = np.clip(img, 0, 1)\n",
    "\n",
    "                plt.subplot(2, 3, images_shown + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Pred: {class_names[preds[i]]}\\nTrue: {class_names[labels[i]]}\")\n",
    "                plt.axis('off')\n",
    "\n",
    "                images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Call the function to visualize predictions\n",
    "visualize_predictions(meta_model, resnet_feat_extractor, mobilenet_feat_extractor, dataloaders['test'], class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ab58227",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:35:30.237986Z",
     "iopub.status.busy": "2025-07-26T10:35:30.237635Z",
     "iopub.status.idle": "2025-07-26T10:35:31.283196Z",
     "shell.execute_reply": "2025-07-26T10:35:31.282250Z",
     "shell.execute_reply.started": "2025-07-26T10:35:30.237958Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Helper function to display predictions\n",
    "def visualize_predictions(meta_model, feat_extractor1, feat_extractor2, dataloader, class_names, num_images=6):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            feats1 = feat_extractor1(inputs).cpu().numpy()\n",
    "            feats2 = feat_extractor2(inputs).cpu().numpy()\n",
    "            combined_feats = np.hstack([feats1, feats2])\n",
    "\n",
    "            preds = meta_model.predict(combined_feats)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                img = inputs[i].cpu().permute(1, 2, 0).numpy()\n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # unnormalize\n",
    "                img = np.clip(img, 0, 1)\n",
    "\n",
    "                plt.subplot(2, 3, images_shown + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Pred: {class_names[preds[i]]}\\nTrue: {class_names[labels[i]]}\")\n",
    "                plt.axis('off')\n",
    "\n",
    "                images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ✅ Call the function\n",
    "visualize_predictions(meta_model, resnet_feat_extractor, mobilenet_feat_extractor, dataloaders['test'], class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bf4fd9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:35:54.191312Z",
     "iopub.status.busy": "2025-07-26T10:35:54.190965Z",
     "iopub.status.idle": "2025-07-26T10:35:56.690855Z",
     "shell.execute_reply": "2025-07-26T10:35:56.689831Z",
     "shell.execute_reply.started": "2025-07-26T10:35:54.191288Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Updated visualization function\n",
    "def visualize_predictions(meta_model, feat_extractor1, feat_extractor2, dataloader, class_names, num_images=6):\n",
    "    images_shown = 0\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in dataloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.numpy()\n",
    "\n",
    "            # Get and flatten features\n",
    "            feats1 = feat_extractor1(inputs).cpu()\n",
    "            feats2 = feat_extractor2(inputs).cpu()\n",
    "\n",
    "            feats1_flat = feats1.view(feats1.size(0), -1).numpy()\n",
    "            feats2_flat = feats2.view(feats2.size(0), -1).numpy()\n",
    "\n",
    "            combined_feats = np.hstack([feats1_flat, feats2_flat])\n",
    "            preds = meta_model.predict(combined_feats)\n",
    "\n",
    "            for i in range(inputs.size(0)):\n",
    "                if images_shown >= num_images:\n",
    "                    break\n",
    "                img = inputs[i].cpu().permute(1, 2, 0).numpy()\n",
    "                img = img * np.array([0.229, 0.224, 0.225]) + np.array([0.485, 0.456, 0.406])  # unnormalize\n",
    "                img = np.clip(img, 0, 1)\n",
    "\n",
    "                plt.subplot(2, 3, images_shown + 1)\n",
    "                plt.imshow(img)\n",
    "                plt.title(f\"Pred: {class_names[preds[i]]}\\nTrue: {class_names[labels[i]]}\")\n",
    "                plt.axis('off')\n",
    "\n",
    "                images_shown += 1\n",
    "            if images_shown >= num_images:\n",
    "                break\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# ✅ Call it\n",
    "visualize_predictions(meta_model, resnet_feat_extractor, mobilenet_feat_extractor, dataloaders['test'], class_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35f2ee6d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:38:58.188404Z",
     "iopub.status.busy": "2025-07-26T10:38:58.188076Z",
     "iopub.status.idle": "2025-07-26T10:38:58.650241Z",
     "shell.execute_reply": "2025-07-26T10:38:58.648980Z",
     "shell.execute_reply.started": "2025-07-26T10:38:58.188381Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# 1. Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# 2. Correct vs Incorrect Predictions\n",
    "correct = sum(np.array(true_labels) == np.array(pred_labels))\n",
    "incorrect = len(true_labels) - correct\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=[\"Correct\", \"Incorrect\"], y=[correct, incorrect], palette=\"pastel\")\n",
    "plt.title(\"Correct vs Incorrect Predictions\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb4020c8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:36:17.400716Z",
     "iopub.status.busy": "2025-07-26T10:36:17.400409Z",
     "iopub.status.idle": "2025-07-26T10:36:18.426287Z",
     "shell.execute_reply": "2025-07-26T10:36:18.425446Z",
     "shell.execute_reply.started": "2025-07-26T10:36:17.400693Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Switch to evaluation mode for feature extractors\n",
    "resnet_feat_extractor.eval()\n",
    "mobilenet_feat_extractor.eval()\n",
    "\n",
    "# Extract features from test set\n",
    "features1_test, labels_test = get_flat_features(resnet_feat_extractor, dataloaders['test'])\n",
    "features2_test, _ = get_flat_features(mobilenet_feat_extractor, dataloaders['test'])\n",
    "\n",
    "# Stack features\n",
    "X_test = np.hstack([features1_test, features2_test])\n",
    "\n",
    "# Predict using the trained meta-model\n",
    "y_pred = meta_model.predict(X_test)\n",
    "\n",
    "# Compute accuracy\n",
    "acc = accuracy_score(labels_test, y_pred)\n",
    "print(f\"✅ Test Accuracy of Stacked Model: {acc * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b72b6ffd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:26.008762Z",
     "iopub.status.busy": "2025-07-26T10:39:26.007957Z",
     "iopub.status.idle": "2025-07-26T10:39:26.025546Z",
     "shell.execute_reply": "2025-07-26T10:39:26.024315Z",
     "shell.execute_reply.started": "2025-07-26T10:39:26.008736Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(\"True Labels:\", true_labels)\n",
    "print(\"Predicted Labels:\", pred_labels)\n",
    "print(\"Number of True Labels:\", len(true_labels))\n",
    "print(\"Number of Predicted Labels:\", len(pred_labels))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bbbc03a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:43.773851Z",
     "iopub.status.busy": "2025-07-26T10:39:43.773549Z",
     "iopub.status.idle": "2025-07-26T10:39:44.721024Z",
     "shell.execute_reply": "2025-07-26T10:39:44.720065Z",
     "shell.execute_reply.started": "2025-07-26T10:39:43.773829Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Ensure model is in evaluation mode\n",
    "resnet_feat_extractor.eval()\n",
    "mobilenet_feat_extractor.eval()\n",
    "\n",
    "true_labels = []\n",
    "pred_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in tqdm(dataloaders['test']):\n",
    "        inputs = inputs.to(device)\n",
    "        feats1 = resnet_feat_extractor(inputs).cpu().numpy()\n",
    "        feats2 = mobilenet_feat_extractor(inputs).cpu().numpy()\n",
    "\n",
    "        # Match shapes if needed (flatten or average pool if needed)\n",
    "        if len(feats1.shape) > 2:\n",
    "            feats1 = feats1.reshape(feats1.shape[0], -1)\n",
    "        if len(feats2.shape) > 2:\n",
    "            feats2 = feats2.reshape(feats2.shape[0], -1)\n",
    "\n",
    "        combined_feats = np.hstack([feats1, feats2])\n",
    "        preds = meta_model.predict(combined_feats)\n",
    "\n",
    "        pred_labels.extend(preds)\n",
    "        true_labels.extend(labels.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa46dcd9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-26T10:39:56.318864Z",
     "iopub.status.busy": "2025-07-26T10:39:56.318552Z",
     "iopub.status.idle": "2025-07-26T10:39:56.761091Z",
     "shell.execute_reply": "2025-07-26T10:39:56.759967Z",
     "shell.execute_reply.started": "2025-07-26T10:39:56.318841Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(true_labels, pred_labels)\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm)\n",
    "disp.plot(cmap='Blues', values_format='d')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n",
    "\n",
    "# Correct vs Incorrect Bar Plot\n",
    "correct = sum(np.array(true_labels) == np.array(pred_labels))\n",
    "incorrect = len(true_labels) - correct\n",
    "\n",
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=[\"Correct\", \"Incorrect\"], y=[correct, incorrect], palette=\"pastel\")\n",
    "plt.title(\"Correct vs Incorrect Predictions\")\n",
    "plt.ylabel(\"Number of Samples\")\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 836844,
     "sourceId": 1428855,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31089,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 53.109751,
   "end_time": "2025-07-26T10:46:01.849419",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-07-26T10:45:08.739668",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
